{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7dbf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./.venv/lib/python3.9/site-packages (8.4.14)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (7.2.2)\n",
      "Requirement already satisfied: polars>=0.20.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (1.36.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.9/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (4.13.0.92)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (3.9.4)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.9/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.9/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (0.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (26.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.23.0)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in ./.venv/lib/python3.9/site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
      "You should consider upgrading via the '/Users/mariaplatek/projects/AXION/YOLOv11/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.9/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./.venv/lib/python3.9/site-packages (from opencv-python-headless) (2.0.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.60.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
      "You should consider upgrading via the '/Users/mariaplatek/projects/AXION/YOLOv11/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installation complete.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "\n",
    "%pip install opencv-python-headless matplotlib\n",
    "\n",
    "print(\"Installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1157cd8e-7938-4a3a-8087-e7422755b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe54aee1-5e2b-4c6e-a140-d2fed0daa637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Silicon (MPS) detected!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"NVIDIA GPU (CUDA) detected.\")\n",
    "    device = \"cuda:0\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Apple Silicon (MPS) detected!\")\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    print(\"Using CPU.\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98605da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"weights/best.pt\"\n",
    "dataset_yaml = \"dataset/data.yaml\"\n",
    "test_images_dir = \"dataset/images/test\"\n",
    "test_labels_dir = \"dataset/labels/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e11d80cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from yolo26m_v3_512/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(best_model_path):\n",
    "    model = YOLO(best_model_path)\n",
    "    print(f\"Model loaded successfully from {best_model_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Could not find model at {best_model_path}. Check your training output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Evaluation on Test Set using mps...\n",
      "Ultralytics 8.4.14 ðŸš€ Python-3.9.6 torch-2.8.0 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 323.1Â±75.2 MB/s, size: 101.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/mariaplatek/projects/AXION/YOLOv11/dataset/labels/test.cache... 1968 images, 1417 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1968/1968 1.0Git/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 123/123 3.2it/s 38.4s0.3s\n",
      "                   all       1968       1427      0.673      0.693       0.71      0.362\n",
      "Speed: 0.1ms preprocess, 14.2ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/mariaplatek/projects/AXION/YOLOv11/runs/detect/val11\u001b[0m\n",
      "\n",
      "--- FINAL METRICS ---\n",
      "mAP@50:    70.98%\n",
      "mAP@50-95: 36.19%\n",
      "Precision: 67.27%\n",
      "Recall:    69.31%\n",
      "F1 Score: 68.27%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nRunning Evaluation on Test Set using {device}...\")\n",
    "metrics = model.val(\n",
    "    data=dataset_yaml, \n",
    "    split='test', \n",
    "    device=device,\n",
    "    plots=True\n",
    ")\n",
    "f1_mean = np.mean(metrics.box.f1)\n",
    "\n",
    "print(\"\\n--- FINAL METRICS ---\")\n",
    "print(f\"mAP@50:    {metrics.box.map50:.2%}\")\n",
    "print(f\"mAP@50-95: {metrics.box.map:.2%}\")\n",
    "print(f\"Precision: {metrics.box.mp:.2%}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.2%}\")\n",
    "print(f\"F1 Score: {f1_mean:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67554f22-f1e1-4e75-ad9f-1a46e5a56b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running prediction on sample: dataset/images/test/cadica_p37_v1_p37_v1_00022.png\n",
      "\n",
      "image 1/1 /Users/mariaplatek/projects/AXION/YOLOv11/dataset/images/test/cadica_p37_v1_p37_v1_00022.png: 512x512 1 stenosis, 14.8ms\n",
      "Speed: 1.0ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "--- RAW MODEL OUTPUT ---\n",
      "Coordinates (xyxy): [[231.77587890625, 127.27021026611328, 310.22900390625, 174.7377471923828]]\n",
      "Confidence scores: [0.4400663375854492]\n",
      "Class IDs: [0.0]\n"
     ]
    }
   ],
   "source": [
    "# --- Dynamic Prediction ---\n",
    "model.to(device)\n",
    "\n",
    "# Grab the first available image in the test directory dynamically\n",
    "test_images = glob.glob(os.path.join(test_images_dir, \"*.png\"))\n",
    "\n",
    "if test_images:\n",
    "    sample_image = test_images[0]\n",
    "    print(f\"\\nRunning prediction on sample: {sample_image}\")\n",
    "    \n",
    "    results = model.predict(\n",
    "        sample_image, \n",
    "        conf=0.1, #change to higher when trained model\n",
    "        device=device,\n",
    "        half=False\n",
    "    )\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        print(\"\\n--- RAW MODEL OUTPUT ---\")\n",
    "        print(f\"Coordinates (xyxy): {boxes.xyxy.tolist()}\") \n",
    "        print(f\"Confidence scores: {boxes.conf.tolist()}\")\n",
    "        print(f\"Class IDs: {boxes.cls.tolist()}\")\n",
    "else:\n",
    "    print(f\"Warning: No .png images found in {test_images_dir}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f0201f2-dcdc-4d01-bac6-97ed3c502f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Average IoU using (TP / TP+FP+FN)...\n",
      "\n",
      "--> Evaluated 1153 True Positive detections.\n",
      "--> Average Box Overlap (IoU): 70.59%\n"
     ]
    }
   ],
   "source": [
    "def calculate_single_iou_by_area(boxA, boxB):\n",
    "    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])\n",
    "    xB, yB = min(boxA[2], boxB[2]), min(boxA[3], boxB[3])\n",
    "\n",
    "    # 1. Calculate TP (True Positive area) -> The Intersection\n",
    "    TP = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    # Calculate the total area of each individual box\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]) # Predicted Box\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]) # Ground Truth Box\n",
    "    \n",
    "    # Calculate FP (False Positive area) -> Predicted area minus Intersection\n",
    "    FP = boxAArea - TP\n",
    "    \n",
    "    # Calculate FN (False Negative area) -> Ground Truth area minus Intersection\n",
    "    FN = boxBArea - TP\n",
    "    \n",
    "    # IoU = TP / (TP + FP + FN)\n",
    "    denominator = TP + FP + FN\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return TP / denominator\n",
    "\n",
    "def get_average_iou(model, test_images_dir, test_labels_dir):\n",
    "    print(\"\\nCalculating Average IoU using (TP / TP+FP+FN)...\")\n",
    "    total_iou = 0\n",
    "    true_positives = 0\n",
    "\n",
    "    image_paths = []\n",
    "    for ext in ('*.jpg', '*.jpeg', '*.png'):\n",
    "        image_paths.extend(glob.glob(os.path.join(test_images_dir, ext)))\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        # prediction\n",
    "        results = model(img_path, device=device, verbose=False)\n",
    "        pred_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        img_h, img_w = results[0].orig_shape \n",
    "        \n",
    "        filename = os.path.basename(img_path)\n",
    "        label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        label_path = os.path.join(test_labels_dir, label_filename)\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            continue \n",
    "            \n",
    "        gt_boxes = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    _, cx_n, cy_n, w_n, h_n = map(float, parts[:5])\n",
    "                    cx, cy = cx_n * img_w, cy_n * img_h\n",
    "                    w, h = w_n * img_w, h_n * img_h\n",
    "                    x1, y1 = cx - w/2, cy - h/2\n",
    "                    x2, y2 = cx + w/2, cy + h/2\n",
    "                    gt_boxes.append([x1, y1, x2, y2])\n",
    "        \n",
    "        for p_box in pred_boxes:\n",
    "            best_iou = 0\n",
    "            for g_box in gt_boxes:\n",
    "                # Use the new explicit TP/FP/FN function\n",
    "                iou = calculate_single_iou_by_area(p_box, g_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "            \n",
    "            # If overlap is 50% or higher, count it as a True Positive\n",
    "            if best_iou >= 0.50:\n",
    "                total_iou += best_iou\n",
    "                true_positives += 1\n",
    "\n",
    "    if true_positives > 0:\n",
    "        avg_iou = total_iou / true_positives\n",
    "        print(f\"\\n--> Evaluated {true_positives} True Positive detections.\")\n",
    "        print(f\"--> Average Box Overlap (IoU): {avg_iou*100:.2f}%\")\n",
    "    else:\n",
    "        print(\"\\n--> No valid detections found to calculate IoU.\")\n",
    "\n",
    "get_average_iou(model, test_images_dir, test_labels_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
