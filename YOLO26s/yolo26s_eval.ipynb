{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation Pipeline Overview\n",
        "Following the training phase, the rigorous evaluation of the model is handled by this script. The objective is not only to rely on high-level metrics but to analyze the raw outputs and manually verify the intersection over union (IoU). This ensures it is understood exactly how well stenotic lesions are localized by the model."
      ],
      "metadata": {
        "id": "WbgAfH8pPum6"
      },
      "id": "WbgAfH8pPum6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7dbf00",
      "metadata": {
        "id": "8f7dbf00",
        "outputId": "86d3c722-f23b-4ec6-da34-9b9352c952f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in ./.venv/lib/python3.9/site-packages (8.4.14)\n",
            "Requirement already satisfied: roboflow in ./.venv/lib/python3.9/site-packages (1.2.14)\n",
            "Requirement already satisfied: psutil>=5.8.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (7.2.2)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (0.23.0)\n",
            "Requirement already satisfied: polars>=0.20.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (1.36.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (3.9.4)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.9/site-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.9/site-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.8.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.9/site-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (4.13.0.92)\n",
            "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.9/site-packages (from ultralytics) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in ./.venv/lib/python3.9/site-packages (from roboflow) (4.67.3)\n",
            "Requirement already satisfied: idna==3.7 in ./.venv/lib/python3.9/site-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from roboflow) (2026.1.4)\n",
            "Requirement already satisfied: cycler in ./.venv/lib/python3.9/site-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: six in ./.venv/lib/python3.9/site-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in ./.venv/lib/python3.9/site-packages (from roboflow) (2.6.3)\n",
            "Requirement already satisfied: requests-toolbelt in ./.venv/lib/python3.9/site-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in ./.venv/lib/python3.9/site-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.9/site-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in ./.venv/lib/python3.9/site-packages (from roboflow) (1.5.5)\n",
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.9/site-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: filetype in ./.venv/lib/python3.9/site-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.2)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (26.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.23.0)\n",
            "Requirement already satisfied: polars-runtime-32==1.36.1 in ./.venv/lib/python3.9/site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
            "You should consider upgrading via the '/Users/mariaplatek/projects/AXION/YOLOv11/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.9/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in ./.venv/lib/python3.9/site-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.60.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
            "You should consider upgrading via the '/Users/mariaplatek/projects/AXION/YOLOv11/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "âœ… Installation complete.\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-python-headless matplotlib\n",
        "\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1157cd8e-7938-4a3a-8087-e7422755b70c",
      "metadata": {
        "id": "1157cd8e-7938-4a3a-8087-e7422755b70c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe54aee1-5e2b-4c6e-a140-d2fed0daa637",
      "metadata": {
        "id": "fe54aee1-5e2b-4c6e-a140-d2fed0daa637",
        "outputId": "875a1c52-0994-470b-cb5a-3fbe704ac2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple Silicon (MPS) detected!\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"NVIDIA GPU (CUDA) detected.\")\n",
        "    device = \"cuda:0\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    print(\"Apple Silicon (MPS) detected!\")\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    print(\"Using CPU.\")\n",
        "    device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hardware Initialization & Standard Validation\n",
        "The best.pt weights generated from the training phase are loaded, and the standard YOLO validation method is executed against the unseen test split. A reliable baseline of the model's performance is thereby established, outputting the standard Mean Average Precision (mAP@50 and mAP@50-95), Precision, Recall and F1 scores."
      ],
      "metadata": {
        "id": "CwSEKcL7P0b1"
      },
      "id": "CwSEKcL7P0b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd9a967b",
      "metadata": {
        "id": "fd9a967b",
        "outputId": "958c5ca3-4ea9-4a7d-b378-343e5a62eff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Evaluation on Test Set using mps...\n",
            "Ultralytics 8.4.14 ðŸš€ Python-3.9.6 torch-2.8.0 MPS (Apple M4 Pro)\n",
            "YOLO26s summary (fused): 122 layers, 9,465,567 parameters, 0 gradients, 20.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 255.5Â±75.5 MB/s, size: 91.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/mariaplatek/projects/AXION/YOLOv11/YOLO26s/dataset/test/labels... 821 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 821/821 5.3Kit/s 0.2s0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/mariaplatek/projects/AXION/YOLOv11/YOLO26s/dataset/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 52/52 3.6it/s 14.3s0.3s\n",
            "                   all        821        821       0.96      0.936      0.972      0.495\n",
            "Speed: 0.1ms preprocess, 8.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
            "Results saved to \u001b[1m/Users/mariaplatek/projects/AXION/YOLOv11/YOLO26s/runs/detect/val\u001b[0m\n",
            "\n",
            "--- FINAL METRICS ---\n",
            "mAP@50:    97.22%\n",
            "mAP@50-95: 49.52%\n",
            "Precision: 96.00%\n",
            "Recall:    93.61%\n",
            "F1: 93.61%\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"weights/best.pt\")\n",
        "\n",
        "print(f\"\\nRunning Evaluation on Test Set using {device}...\")\n",
        "metrics = model.val(\n",
        "    data=\"dataset/data.yaml\",\n",
        "    split='test',\n",
        "    device=device,\n",
        "    plots=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- FINAL METRICS ---\")\n",
        "print(f\"mAP@50:    {metrics.box.map50:.2%}\")\n",
        "print(f\"mAP@50-95: {metrics.box.map:.2%}\")\n",
        "print(f\"Precision: {metrics.box.mp:.2%}\")\n",
        "print(f\"Recall:    {metrics.box.mr:.2%}\")\n",
        "\n",
        "f1_mean = np.mean(metrics.box.f1)\n",
        "print(f\"F1 Score: {f1_mean:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0140c8-cbfd-474e-9722-959bd15e295c",
      "metadata": {
        "id": "fa0140c8-cbfd-474e-9722-959bd15e295c"
      },
      "outputs": [],
      "source": [
        "images_dir = \"dataset/test/images\"\n",
        "labels_dir = \"dataset/test/labels\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dynamic Sample Prediction\n",
        "To verify the practical functionality of the model, a dynamic prediction block is implemented. The first available .jpg image from the test set is automatically retrieved, and a live inference is run with a confidence threshold of 0.5.\n",
        "\n",
        "**Coordinates (xyxy):** The exact pixel locations of the bounding box corners are displayed.\n",
        "These represent the exact pixel locations of the bounding box drawn around the detected object.\n",
        "The format is `[x_min, y_min, x_max, y_max]`.\n",
        "\n",
        "**Confidence Scores:** The certainty that the detected object is a stenosis is evaluated and printed.\n",
        "\n",
        "**Class IDs:** The correct label category prediction is verified."
      ],
      "metadata": {
        "id": "_bF9FxztQMX5"
      },
      "id": "_bF9FxztQMX5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67554f22-f1e1-4e75-ad9f-1a46e5a56b5d",
      "metadata": {
        "id": "67554f22-f1e1-4e75-ad9f-1a46e5a56b5d",
        "outputId": "ff7f33f4-6ef3-4f6f-9c38-70c82d02dfee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running prediction on sample: dataset/test/images/14_031_5_0036_bmp.rf.97d1144ba125963340270c5b4f390754.jpg\n",
            "\n",
            "image 1/1 /Users/mariaplatek/projects/AXION/YOLOv11/YOLO26s/dataset/test/images/14_031_5_0036_bmp.rf.97d1144ba125963340270c5b4f390754.jpg: 640x640 1 Stenosis, 14.5ms\n",
            "Speed: 4.1ms preprocess, 14.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "--- RAW MODEL OUTPUT ---\n",
            "Coordinates (xyxy): [[488.6090087890625, 191.39208984375, 525.1990966796875, 226.6587677001953]]\n",
            "Confidence scores: [0.8094199299812317]\n",
            "Class IDs: [0.0]\n"
          ]
        }
      ],
      "source": [
        "# --- Dynamic Prediction ---\n",
        "model.to(device)\n",
        "\n",
        "# Grab the first available image in the test directory dynamically\n",
        "test_images = glob.glob(os.path.join(images_dir, \"*.jpg\"))\n",
        "\n",
        "if test_images:\n",
        "    sample_image = test_images[0]\n",
        "    print(f\"\\nRunning prediction on sample: {sample_image}\")\n",
        "\n",
        "    results = model.predict(\n",
        "        sample_image,\n",
        "        conf=0.5,\n",
        "        device=device,\n",
        "        half=False\n",
        "    )\n",
        "\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        print(\"\\n--- RAW MODEL OUTPUT ---\")\n",
        "        print(f\"Coordinates (xyxy): {boxes.xyxy.tolist()}\")\n",
        "        print(f\"Confidence scores: {boxes.conf.tolist()}\")\n",
        "        print(f\"Class IDs: {boxes.cls.tolist()}\")\n",
        "else:\n",
        "    print(f\"Warning: No .jpg images found in {images_dir}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom Intersection over Union (IoU) Engine\n",
        "While standard metrics are utilized, granular control over how bounding box accuracy is calculated was required. To achieve this, a custom mathematical function was developed to calculate the Intersection over Union (IoU) using True Positives (TP), False Positives (FP), and False Negatives (FN) based on box areas."
      ],
      "metadata": {
        "id": "qqHUuguFQkhp"
      },
      "id": "qqHUuguFQkhp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0201f2-dcdc-4d01-bac6-97ed3c502f49",
      "metadata": {
        "id": "8f0201f2-dcdc-4d01-bac6-97ed3c502f49",
        "outputId": "5b4d37a9-3658-49c9-8b82-f26905cb5d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating Average IoU using (TP / TP+FP+FN)...\n",
            "\n",
            "--> Evaluated 788 True Positive detections.\n",
            "--> Average Box Overlap (IoU): 75.04%\n"
          ]
        }
      ],
      "source": [
        "def calculate_single_iou_by_area(boxA, boxB):\n",
        "    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])\n",
        "    xB, yB = min(boxA[2], boxB[2]), min(boxA[3], boxB[3])\n",
        "\n",
        "    # 1. Calculate TP (True Positive area) -> The Intersection\n",
        "    TP = max(0, xB - xA) * max(0, yB - yA)\n",
        "\n",
        "    # Calculate the total area of each individual box\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]) # Predicted Box\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]) # Ground Truth Box\n",
        "\n",
        "    # Calculate FP (False Positive area) -> Predicted area minus Intersection\n",
        "    FP = boxAArea - TP\n",
        "\n",
        "    # Calculate FN (False Negative area) -> Ground Truth area minus Intersection\n",
        "    FN = boxBArea - TP\n",
        "\n",
        "    # IoU = TP / (TP + FP + FN)\n",
        "    denominator = TP + FP + FN\n",
        "\n",
        "    if denominator == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return TP / denominator\n",
        "\n",
        "def get_average_iou(model, images_dir, labels_dir):\n",
        "    print(\"\\nCalculating Average IoU using (TP / TP+FP+FN)...\")\n",
        "    total_iou = 0\n",
        "    true_positives = 0\n",
        "\n",
        "    image_paths = []\n",
        "    for ext in ('*.jpg', '*.jpeg', '*.png'):\n",
        "        image_paths.extend(glob.glob(os.path.join(images_dir, ext)))\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        # prediction\n",
        "        results = model(img_path, device=device, verbose=False)\n",
        "        pred_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "        img_h, img_w = results[0].orig_shape\n",
        "\n",
        "        filename = os.path.basename(img_path)\n",
        "        label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "        label_path = os.path.join(labels_dir, label_filename)\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        gt_boxes = []\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    _, cx_n, cy_n, w_n, h_n = map(float, parts[:5])\n",
        "                    cx, cy = cx_n * img_w, cy_n * img_h\n",
        "                    w, h = w_n * img_w, h_n * img_h\n",
        "                    x1, y1 = cx - w/2, cy - h/2\n",
        "                    x2, y2 = cx + w/2, cy + h/2\n",
        "                    gt_boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "        for p_box in pred_boxes:\n",
        "            best_iou = 0\n",
        "            for g_box in gt_boxes:\n",
        "                # Use the new explicit TP/FP/FN function\n",
        "                iou = calculate_single_iou_by_area(p_box, g_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "\n",
        "            # If overlap is 50% or higher, count it as a True Positive\n",
        "            if best_iou >= 0.50:\n",
        "                total_iou += best_iou\n",
        "                true_positives += 1\n",
        "\n",
        "    if true_positives > 0:\n",
        "        avg_iou = total_iou / true_positives\n",
        "        print(f\"\\n--> Evaluated {true_positives} True Positive detections.\")\n",
        "        print(f\"--> Average Box Overlap (IoU): {avg_iou*100:.2f}%\")\n",
        "    else:\n",
        "        print(\"\\n--> No valid detections found to calculate IoU.\")\n",
        "\n",
        "get_average_iou(model, images_dir, labels_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}