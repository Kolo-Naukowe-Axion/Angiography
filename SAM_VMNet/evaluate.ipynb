{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM-VMNet Comprehensive Evaluation\n",
    "\n",
    "Runs inference on the test set, computes rich per-image and global metrics, and generates 7 publication-quality charts + a JSON report.\n",
    "\n",
    "**Outputs** (saved to `OUTPUT_DIR`):\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `confusion_matrix.png` | Annotated heatmap with counts + percentages |\n",
    "| `precision_recall_curve.png` | PR curve with mAP, iso-F1 reference lines |\n",
    "| `roc_curve.png` | ROC curve with AUC, diagonal baseline |\n",
    "| `metric_distributions.png` | Violin+box+strip plots for Dice, IoU, HD95, ASD |\n",
    "| `threshold_analysis.png` | F1/IoU/Precision/Recall across thresholds 0.1–0.9 |\n",
    "| `qualitative_results.png` | Best 4 + worst 4 predictions grid |\n",
    "| `metrics_dashboard.png` | Clean summary table of all aggregate metrics |\n",
    "| `metrics.json` | Full metrics (global + per-image) for programmatic use |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Edit the variables below before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ========================= EDIT THESE =========================\nBRANCH      = 2                    # 1 = VM-UNet, 2 = SAM-VMNet\nDATA_PATH   = './data/vessel/'     # dataset root\nWEIGHTS     = './saved/branch2/checkpoints/best-epoch77-loss0.7787.pth'\nTHRESHOLD   = 0.5                  # binarization threshold\nOUTPUT_DIR  = './evaluation/'      # where charts + JSON are saved\nBATCH_SIZE  = 1                    # inference batch size\nDEVICE      = None                 # None = auto-detect, or 'cuda:0' / 'mps' / 'cpu'\n# =============================================================="
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (1.13.1)\n",
      "Requirement already satisfied: matplotlib in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (3.9.4)\n",
      "Requirement already satisfied: Pillow in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (11.3.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.13.0.92-cp37-abi3-macosx_13_0_arm64.whl (46.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 46.2 MB 200 kB/s eta 0:00:012\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-macosx_12_0_arm64.whl (13.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: h5py in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (3.14.0)\n",
      "Requirement already satisfied: medpy in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (0.5.2)\n",
      "Requirement already satisfied: SimpleITK in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (2.5.3)\n",
      "Requirement already satisfied: tqdm in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (4.67.3)\n",
      "Requirement already satisfied: ipywidgets in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (8.1.8)\n",
      "Requirement already satisfied: einops in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (0.8.2)\n",
      "Requirement already satisfied: timm in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (1.0.24)\n",
      "Requirement already satisfied: thop in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: networkx in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.5)\n",
      "Collecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.33\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "\u001b[K     |████████████████████████████████| 317 kB 15.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=3.1.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: safetensors in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: pyyaml in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from timm) (1.4.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: exceptiongroup in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: stack-data in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: decorator in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: shellingham in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from huggingface_hub->timm) (1.5.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from huggingface_hub->timm) (0.28.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: typer-slim in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from huggingface_hub->timm) (0.23.2)\n",
      "Requirement already satisfied: anyio in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2025.11.12)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: typer>=0.23.2 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from typer-slim->huggingface_hub->timm) (0.23.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from typer>=0.23.2->typer-slim->huggingface_hub->timm) (0.0.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from typer>=0.23.2->typer-slim->huggingface_hub->timm) (8.1.8)\n",
      "Requirement already satisfied: rich>=12.3.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from typer>=0.23.2->typer-slim->huggingface_hub->timm) (14.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from rich>=12.3.0->typer>=0.23.2->typer-slim->huggingface_hub->timm) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/iwosmura/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.23.2->typer-slim->huggingface_hub->timm) (0.1.2)\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image, opencv-python\n",
      "Successfully installed imageio-2.37.2 lazy-loader-0.4 opencv-python-4.13.0.92 scikit-image-0.24.0 tifffile-2024.8.30\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Full dependency chain: notebook -> dataset.py -> utils.py -> med_sam/ -> models/vmamba.py\n",
    "%pip install \\\n",
    "    torch torchvision \\\n",
    "    numpy scipy matplotlib Pillow \\\n",
    "    opencv-python scikit-image scikit-learn \\\n",
    "    h5py medpy SimpleITK \\\n",
    "    tqdm ipywidgets \\\n",
    "    einops timm thop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch:    SAM-VMNet (Branch 2)\n",
      "Data:      ./data/vessel/\n",
      "Weights:   ./best.pth\n",
      "Threshold: 0.5\n",
      "Device:    mps\n",
      "Output:    ./evaluation/\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json, warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from medpy.metric.binary import hd95, assd\n",
    "\n",
    "from dataset import Branch1_datasets, Branch2_datasets\n",
    "from models.vmunet.vmunet import VMUNet\n",
    "from models.vmunet.samvmnet import SAMVMNet\n",
    "from configs.config_setting import setting_config\n",
    "from utils import BceDiceLoss\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------- Color palette & style ----------\n",
    "COLORS = {\n",
    "    'steel_blue':   '#2E86AB',\n",
    "    'deep_rose':    '#A23B72',\n",
    "    'warm_amber':   '#F18F01',\n",
    "    'forest_green': '#3C8C50',\n",
    "}\n",
    "DPI = 300\n",
    "MAX_PIXELS_PR_ROC = 10_000_000\n",
    "RNG_SEED = 42\n",
    "\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except OSError:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Helvetica', 'Arial', 'DejaVu Sans'],\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'figure.dpi': 150,        # screen-friendly; saved PNGs still use DPI=300\n",
    "    'savefig.dpi': DPI,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'savefig.pad_inches': 0.1,\n",
    "})\n",
    "\n",
    "# ---------- Device ----------\n",
    "if DEVICE:\n",
    "    device = torch.device(DEVICE)\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "branch_name = 'VM-UNet (Branch 1)' if BRANCH == 1 else 'SAM-VMNet (Branch 2)'\n",
    "print(f'Branch:    {branch_name}')\n",
    "print(f'Data:      {DATA_PATH}')\n",
    "print(f'Weights:   {WEIGHTS}')\n",
    "print(f'Threshold: {THRESHOLD}')\n",
    "print(f'Device:    {device}')\n",
    "print(f'Output:    {OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     model \u001b[38;5;241m=\u001b[39m SAMVMNet(\n\u001b[1;32m     14\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m         input_channels\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_channels\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         load_ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     )\n\u001b[0;32m---> 22\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     24\u001b[0m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_ops\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_params\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k}\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/serialization.py:1484\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1482\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './best.pth'"
     ]
    }
   ],
   "source": [
    "cfg = setting_config.model_config\n",
    "\n",
    "if BRANCH == 1:\n",
    "    model = VMUNet(\n",
    "        num_classes=cfg['num_classes'],\n",
    "        input_channels=cfg['input_channels'],\n",
    "        depths=cfg['depths'],\n",
    "        depths_decoder=cfg['depths_decoder'],\n",
    "        drop_path_rate=cfg['drop_path_rate'],\n",
    "        load_ckpt_path=None,\n",
    "    )\n",
    "else:\n",
    "    model = SAMVMNet(\n",
    "        num_classes=cfg['num_classes'],\n",
    "        input_channels=cfg['input_channels'],\n",
    "        depths=cfg['depths'],\n",
    "        depths_decoder=cfg['depths_decoder'],\n",
    "        drop_path_rate=cfg['drop_path_rate'],\n",
    "        load_ckpt_path=None,\n",
    "    )\n",
    "\n",
    "state_dict = torch.load(WEIGHTS, map_location='cpu', weights_only=False)\n",
    "state_dict = {k: v for k, v in state_dict.items()\n",
    "              if 'total_ops' not in k and 'total_params' not in k}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.to(device)\n",
    "model.device = device\n",
    "model.eval()\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "print(f'Model loaded on {device}  ({n_params:.2f}M parameters)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BRANCH == 1:\n",
    "    test_dataset = Branch1_datasets(DATA_PATH, setting_config, train=False, test=True)\n",
    "else:\n",
    "    test_dataset = Branch2_datasets(DATA_PATH, setting_config, train=False, test=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(f'{len(test_dataset)} test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Inference\n",
    "\n",
    "Collects per-image raw probabilities, ground truths, input images, and loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BceDiceLoss(wb=1, wd=1)\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Inference'):\n",
    "        if BRANCH == 1:\n",
    "            img, msk = data\n",
    "            img = img.to(device, non_blocking=True).float()\n",
    "            msk = msk.to(device, non_blocking=True).float()\n",
    "            out = model(img)\n",
    "        else:\n",
    "            img, msk, feature = data\n",
    "            img = img.to(device, non_blocking=True).float()\n",
    "            msk = msk.to(device, non_blocking=True).float()\n",
    "            feature = feature.to(device, non_blocking=True).float()\n",
    "            out = model(img, feature)\n",
    "\n",
    "        if isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "\n",
    "        loss = criterion(out.float().clamp(1e-7, 1 - 1e-7), msk)\n",
    "\n",
    "        for b in range(img.size(0)):\n",
    "            results.append({\n",
    "                'prob':  out[b].squeeze(0).cpu().numpy().astype(np.float32),\n",
    "                'gt':    msk[b].squeeze(0).cpu().numpy().astype(np.float32),\n",
    "                'image': img[b].cpu().numpy().astype(np.float32),\n",
    "                'loss':  loss.item(),\n",
    "            })\n",
    "\n",
    "print(f'Collected {len(results)} predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Metrics\n",
    "\n",
    "### 5a. Per-Image Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_image_metrics(prob, gt, threshold):\n",
    "    \"\"\"Dice, IoU, Precision, Recall, Specificity, Accuracy, HD95, ASD for one image.\"\"\"\n",
    "    pred   = (prob >= threshold).astype(np.uint8)\n",
    "    gt_bin = (gt   >= 0.5).astype(np.uint8)\n",
    "\n",
    "    tp = float(np.sum( pred &  gt_bin))\n",
    "    fp = float(np.sum( pred & ~gt_bin))\n",
    "    fn = float(np.sum(~pred &  gt_bin))\n",
    "    tn = float(np.sum(~pred & ~gt_bin))\n",
    "\n",
    "    dice        = (2*tp) / (2*tp + fp + fn) if (2*tp + fp + fn) > 0 else 0.0\n",
    "    iou         = tp / (tp + fp + fn)       if (tp + fp + fn)   > 0 else 0.0\n",
    "    precision   = tp / (tp + fp)            if (tp + fp)        > 0 else 0.0\n",
    "    recall      = tp / (tp + fn)            if (tp + fn)        > 0 else 0.0\n",
    "    specificity = tn / (tn + fp)            if (tn + fp)        > 0 else 0.0\n",
    "    accuracy    = (tp + tn) / (tp+tn+fp+fn) if (tp+tn+fp+fn)   > 0 else 0.0\n",
    "\n",
    "    hd95_val, asd_val = np.nan, np.nan\n",
    "    if pred.sum() > 0 and gt_bin.sum() > 0:\n",
    "        try: hd95_val = hd95(pred, gt_bin)\n",
    "        except Exception: pass\n",
    "        try: asd_val  = assd(pred, gt_bin)\n",
    "        except Exception: pass\n",
    "\n",
    "    return dict(dice=dice, iou=iou, precision=precision, recall=recall,\n",
    "                specificity=specificity, accuracy=accuracy,\n",
    "                hd95=hd95_val, asd=asd_val)\n",
    "\n",
    "\n",
    "per_image_metrics = []\n",
    "for idx, r in enumerate(tqdm(results, desc='Per-image metrics')):\n",
    "    m = compute_per_image_metrics(r['prob'], r['gt'], THRESHOLD)\n",
    "    m['loss']  = r['loss']\n",
    "    m['index'] = idx\n",
    "    per_image_metrics.append(m)\n",
    "\n",
    "print(f'Computed metrics for {len(per_image_metrics)} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Global Pixel-Level Metrics + PR/ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all pixels\n",
    "all_probs = np.concatenate([r['prob'].ravel() for r in results])\n",
    "all_gts   = np.concatenate([(r['gt'] >= 0.5).astype(np.uint8).ravel() for r in results])\n",
    "\n",
    "# Global confusion matrix\n",
    "y_pred_global = (all_probs >= THRESHOLD).astype(np.uint8)\n",
    "cm = confusion_matrix(all_gts, y_pred_global)\n",
    "tn, fp, fn, tp = cm[0,0], cm[0,1], cm[1,0], cm[1,1]\n",
    "\n",
    "global_metrics = {\n",
    "    'dice':        float(2*tp) / float(2*tp+fp+fn)  if (2*tp+fp+fn)   > 0 else 0.0,\n",
    "    'iou':         float(tp)   / float(tp+fp+fn)    if (tp+fp+fn)     > 0 else 0.0,\n",
    "    'precision':   float(tp)   / float(tp+fp)       if (tp+fp)        > 0 else 0.0,\n",
    "    'recall':      float(tp)   / float(tp+fn)       if (tp+fn)        > 0 else 0.0,\n",
    "    'specificity': float(tn)   / float(tn+fp)       if (tn+fp)        > 0 else 0.0,\n",
    "    'accuracy':    float(tn+tp)/ float(np.sum(cm))  if float(np.sum(cm)) > 0 else 0.0,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'mean_loss': float(np.mean([r['loss'] for r in results])),\n",
    "}\n",
    "\n",
    "# Subsample for PR/ROC\n",
    "rng = np.random.RandomState(RNG_SEED)\n",
    "if len(all_probs) > MAX_PIXELS_PR_ROC:\n",
    "    idx_sub   = rng.choice(len(all_probs), MAX_PIXELS_PR_ROC, replace=False)\n",
    "    probs_sub = all_probs[idx_sub]\n",
    "    gts_sub   = all_gts[idx_sub]\n",
    "else:\n",
    "    probs_sub, gts_sub = all_probs, all_gts\n",
    "\n",
    "global_metrics['mAP']     = float(average_precision_score(gts_sub, probs_sub))\n",
    "global_metrics['roc_auc'] = float(roc_auc_score(gts_sub, probs_sub))\n",
    "pr_prec, pr_rec, _  = precision_recall_curve(gts_sub, probs_sub)\n",
    "fpr_arr, tpr_arr, _ = roc_curve(gts_sub, probs_sub)\n",
    "\n",
    "# Per-image mean +/- std\n",
    "for key in ['dice','iou','precision','recall','specificity','accuracy','hd95','asd']:\n",
    "    vals = [m[key] for m in per_image_metrics if not np.isnan(m[key])]\n",
    "    global_metrics[f'{key}_mean'] = float(np.mean(vals)) if vals else float('nan')\n",
    "    global_metrics[f'{key}_std']  = float(np.std(vals))  if vals else float('nan')\n",
    "\n",
    "g = global_metrics\n",
    "print(f'Global -- Dice: {g[\"dice\"]:.4f}  IoU: {g[\"iou\"]:.4f}  '\n",
    "      f'Acc: {g[\"accuracy\"]:.4f}  mAP: {g[\"mAP\"]:.4f}  AUC: {g[\"roc_auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Threshold Sensitivity (0.1 – 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_data = {}\n",
    "for t in np.round(np.arange(0.1, 0.91, 0.05), 2):\n",
    "    y_pred = (all_probs >= t).astype(np.uint8)\n",
    "    c = confusion_matrix(all_gts, y_pred)\n",
    "    tn_, fp_, fn_, tp_ = c[0,0], c[0,1], c[1,0], c[1,1]\n",
    "    threshold_data[t] = {\n",
    "        'f1':        float(2*tp_) / float(2*tp_+fp_+fn_) if (2*tp_+fp_+fn_) > 0 else 0.0,\n",
    "        'iou':       float(tp_)   / float(tp_+fp_+fn_)   if (tp_+fp_+fn_)   > 0 else 0.0,\n",
    "        'precision': float(tp_)   / float(tp_+fp_)       if (tp_+fp_)       > 0 else 0.0,\n",
    "        'recall':    float(tp_)   / float(tp_+fn_)       if (tp_+fn_)       > 0 else 0.0,\n",
    "    }\n",
    "\n",
    "print(f'Computed metrics at {len(threshold_data)} thresholds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Charts\n",
    "\n",
    "Each chart is displayed inline **and** saved to `OUTPUT_DIR` at 300 DPI.\n",
    "\n",
    "### Chart 1 — Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_arr = np.array(global_metrics['confusion_matrix'])\n",
    "cm_pct = cm_arr.astype(float) / cm_arr.sum() * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "im = ax.imshow(cm_pct, cmap='Blues', vmin=0, vmax=100)\n",
    "\n",
    "labels = ['Background (0)', 'Vessel (1)']\n",
    "ax.set_xticks([0, 1]); ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(labels); ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Predicted'); ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        color = 'white' if cm_pct[i, j] > 50 else 'black'\n",
    "        ax.text(j, i, f'{cm_arr[i,j]:,}\\n({cm_pct[i,j]:.1f}%)',\n",
    "                ha='center', va='center', color=color, fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.colorbar(im, ax=ax, label='Percentage (%)')\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart 2 — Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Iso-F1 reference lines\n",
    "for f1_val in [0.2, 0.4, 0.6, 0.8]:\n",
    "    x = np.linspace(0.01, 1, 100)\n",
    "    y = f1_val * x / (2 * x - f1_val)\n",
    "    valid = (y > 0) & (y <= 1)\n",
    "    ax.plot(x[valid], y[valid], '--', color='#CCCCCC', linewidth=0.8, alpha=0.7)\n",
    "    idx_label = np.where(valid)[0]\n",
    "    if len(idx_label) > 0:\n",
    "        li = idx_label[-1]\n",
    "        ax.annotate(f'F1={f1_val}', xy=(x[li], y[li]), fontsize=8, color='#999999')\n",
    "\n",
    "mAP = global_metrics['mAP']\n",
    "ax.plot(pr_rec, pr_prec, color=COLORS['steel_blue'], linewidth=2,\n",
    "        label=f'PR curve (mAP = {mAP:.4f})')\n",
    "ax.fill_between(pr_rec, pr_prec, alpha=0.15, color=COLORS['steel_blue'])\n",
    "ax.set_xlabel('Recall'); ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_xlim([0, 1]); ax.set_ylim([0, 1.05])\n",
    "ax.legend(loc='lower left', fontsize=11)\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'precision_recall_curve.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart 3 — ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_val = global_metrics['roc_auc']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.plot([0, 1], [0, 1], '--', color='#CCCCCC', linewidth=1, label='Random baseline')\n",
    "ax.plot(fpr_arr, tpr_arr, color=COLORS['deep_rose'], linewidth=2,\n",
    "        label=f'ROC curve (AUC = {auc_val:.4f})')\n",
    "ax.fill_between(fpr_arr, tpr_arr, alpha=0.15, color=COLORS['deep_rose'])\n",
    "ax.set_xlabel('False Positive Rate'); ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve')\n",
    "ax.set_xlim([0, 1]); ax.set_ylim([0, 1.05])\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'roc_curve.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart 4 — Per-Image Metric Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys   = ['dice', 'iou', 'hd95', 'asd']\n",
    "display_names = ['Dice', 'IoU', 'HD95', 'ASD']\n",
    "palette = [COLORS['steel_blue'], COLORS['deep_rose'],\n",
    "           COLORS['warm_amber'], COLORS['forest_green']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "for ax, key, name, color in zip(axes, metric_keys, display_names, palette):\n",
    "    vals = [m[key] for m in per_image_metrics if not np.isnan(m[key])]\n",
    "    if not vals:\n",
    "        ax.text(0.5, 0.5, 'N/A', ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.set_title(name); continue\n",
    "\n",
    "    # Violin\n",
    "    parts = ax.violinplot(vals, positions=[0], showextrema=False, widths=0.8)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(color); pc.set_alpha(0.3)\n",
    "\n",
    "    # Box\n",
    "    bp = ax.boxplot(vals, positions=[0], widths=0.3, patch_artist=True,\n",
    "                    showfliers=False, zorder=3)\n",
    "    bp['boxes'][0].set_facecolor(color); bp['boxes'][0].set_alpha(0.6)\n",
    "    bp['medians'][0].set_color('white'); bp['medians'][0].set_linewidth(2)\n",
    "\n",
    "    # Strip (jittered points)\n",
    "    jitter = np.random.RandomState(RNG_SEED).uniform(-0.12, 0.12, len(vals))\n",
    "    ax.scatter(jitter, vals, color=color, alpha=0.5, s=15, zorder=4, edgecolors='none')\n",
    "\n",
    "    ax.set_title(f'{name}\\n{np.mean(vals):.4f} +/- {np.std(vals):.4f}', fontsize=12)\n",
    "    ax.set_xticks([]); ax.set_ylabel(name)\n",
    "\n",
    "fig.suptitle('Per-Image Metric Distributions', fontsize=14, fontweight='bold', y=1.02)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'metric_distributions.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart 5 — Threshold Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = sorted(threshold_data.keys())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(thresholds, [threshold_data[t]['f1']        for t in thresholds],\n",
    "        '-o', color=COLORS['steel_blue'],   label='F1 / Dice',  markersize=5)\n",
    "ax.plot(thresholds, [threshold_data[t]['iou']       for t in thresholds],\n",
    "        '-s', color=COLORS['deep_rose'],    label='IoU',        markersize=5)\n",
    "ax.plot(thresholds, [threshold_data[t]['precision']  for t in thresholds],\n",
    "        '-^', color=COLORS['warm_amber'],   label='Precision',  markersize=5)\n",
    "ax.plot(thresholds, [threshold_data[t]['recall']    for t in thresholds],\n",
    "        '-D', color=COLORS['forest_green'], label='Recall',     markersize=5)\n",
    "\n",
    "ax.axvline(x=THRESHOLD, color='#666666', linestyle='--', linewidth=1,\n",
    "           label=f'Chosen t={THRESHOLD}')\n",
    "\n",
    "ax.set_xlabel('Threshold'); ax.set_ylabel('Score')\n",
    "ax.set_title('Threshold Sensitivity Analysis')\n",
    "ax.set_xlim([0.05, 0.95]); ax.set_ylim([0, 1.05])\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'threshold_analysis.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart 6 — Qualitative Results (Best 4 + Worst 4)\n",
    "\n",
    "Overlay legend: **Green** = TP, **Red** = FP, **Blue** = FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_dice = sorted(per_image_metrics, key=lambda m: m['dice'])\n",
    "worst4 = sorted_by_dice[:4]\n",
    "best4  = sorted_by_dice[-4:][::-1]\n",
    "selected = best4 + worst4\n",
    "row_labels = ['Best'] * 4 + ['Worst'] * 4\n",
    "\n",
    "fig, axes = plt.subplots(len(selected), 4, figsize=(16, 4 * len(selected)))\n",
    "col_titles = ['Input', 'Ground Truth', 'Prediction', 'Overlay']\n",
    "\n",
    "for row, (m, label) in enumerate(zip(selected, row_labels)):\n",
    "    r    = results[m['index']]\n",
    "    img  = r['image']                                        # (3, H, W)\n",
    "    gt   = r['gt']                                           # (H, W)\n",
    "    prob = r['prob']                                         # (H, W)\n",
    "    pred   = (prob >= THRESHOLD).astype(np.uint8)\n",
    "    gt_bin = (gt   >= 0.5).astype(np.uint8)\n",
    "\n",
    "    # Denormalize for display\n",
    "    img_disp = np.transpose(img, (1, 2, 0))\n",
    "    img_disp = (img_disp - img_disp.min()) / (img_disp.max() - img_disp.min() + 1e-8)\n",
    "\n",
    "    # Overlay\n",
    "    overlay = img_disp * 0.4\n",
    "    overlay[ (pred & gt_bin).astype(bool), :] = [0.0, 0.8, 0.0]   # TP green\n",
    "    overlay[ (pred & ~gt_bin).astype(bool), :] = [0.8, 0.0, 0.0]  # FP red\n",
    "    overlay[(~pred & gt_bin).astype(bool), :] = [0.0, 0.0, 0.8]   # FN blue\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "\n",
    "    axes[row, 0].imshow(img_disp)\n",
    "    axes[row, 1].imshow(gt,   cmap='gray', vmin=0, vmax=1)\n",
    "    axes[row, 2].imshow(pred, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[row, 3].imshow(overlay)\n",
    "\n",
    "    for col in range(4):\n",
    "        axes[row, col].axis('off')\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(col_titles[col], fontsize=12, fontweight='bold')\n",
    "\n",
    "    axes[row, 0].set_ylabel(f'{label} #{row % 4 + 1}\\nDice={m[\"dice\"]:.3f}',\n",
    "                            fontsize=10, rotation=0, labelpad=70, va='center')\n",
    "\n",
    "fig.suptitle('Qualitative Results: Best 4 & Worst 4 by Dice',\n",
    "             fontsize=14, fontweight='bold', y=1.01)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'qualitative_results.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart 7 — Metrics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fmt_mean_std(key):\n",
    "    mn = global_metrics.get(f'{key}_mean', float('nan'))\n",
    "    sd = global_metrics.get(f'{key}_std',  float('nan'))\n",
    "    if np.isnan(mn): return 'N/A'\n",
    "    if key in ('hd95', 'asd'):\n",
    "        return f'{mn:.2f} +/- {sd:.2f}'\n",
    "    return f'{mn:.4f} +/- {sd:.4f}'\n",
    "\n",
    "rows = [\n",
    "    ['Dice (F1)',           f'{g[\"dice\"]:.4f}',        _fmt_mean_std('dice')],\n",
    "    ['IoU (Jaccard)',       f'{g[\"iou\"]:.4f}',         _fmt_mean_std('iou')],\n",
    "    ['Precision',           f'{g[\"precision\"]:.4f}',   _fmt_mean_std('precision')],\n",
    "    ['Recall / Sensitivity',f'{g[\"recall\"]:.4f}',      _fmt_mean_std('recall')],\n",
    "    ['Specificity',         f'{g[\"specificity\"]:.4f}', _fmt_mean_std('specificity')],\n",
    "    ['Accuracy',            f'{g[\"accuracy\"]:.4f}',    _fmt_mean_std('accuracy')],\n",
    "    ['HD95 (px)',           '-',                        _fmt_mean_std('hd95')],\n",
    "    ['ASD (px)',            '-',                        _fmt_mean_std('asd')],\n",
    "    ['mAP',                 f'{g[\"mAP\"]:.4f}',        '-'],\n",
    "    ['ROC-AUC',             f'{g[\"roc_auc\"]:.4f}',    '-'],\n",
    "    ['Mean Loss',           f'{g[\"mean_loss\"]:.4f}',  '-'],\n",
    "    ['Threshold',           f'{THRESHOLD}',            '-'],\n",
    "]\n",
    "col_labels = ['Metric', 'Global', 'Per-Image (mean +/- std)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.axis('off')\n",
    "ax.set_title('Evaluation Metrics Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "table = ax.table(cellText=rows, colLabels=col_labels, loc='center', cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.0, 1.6)\n",
    "\n",
    "for j in range(len(col_labels)):\n",
    "    cell = table[0, j]\n",
    "    cell.set_facecolor(COLORS['steel_blue'])\n",
    "    cell.set_text_props(color='white', fontweight='bold')\n",
    "\n",
    "for i in range(1, len(rows) + 1):\n",
    "    for j in range(len(col_labels)):\n",
    "        table[i, j].set_facecolor('#F0F4F8' if i % 2 == 0 else 'white')\n",
    "\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'metrics_dashboard.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Export Metrics JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = {\n",
    "    'threshold': THRESHOLD,\n",
    "    'global': global_metrics,\n",
    "    'threshold_sensitivity': {str(k): v for k, v in threshold_data.items()},\n",
    "    'per_image': [\n",
    "        {k: (v if not (isinstance(v, float) and np.isnan(v)) else None)\n",
    "         for k, v in m.items()}\n",
    "        for m in per_image_metrics\n",
    "    ],\n",
    "}\n",
    "\n",
    "json_path = os.path.join(OUTPUT_DIR, 'metrics.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(export, f, indent=2)\n",
    "\n",
    "print(f'Saved {json_path}  ({os.path.getsize(json_path) / 1024:.1f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Done\n",
    "\n",
    "All 7 charts + `metrics.json` have been saved to the output directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}